{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 解决matplotlib显示中文问题\n",
    "# 仅适用于Windows\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "# MacOS请参考 http://wenda.chinahadoop.cn/question/5304 修改字体配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 指定数据集路径\n",
    "dataset_path = 'D://Study-_Note//NLP//NLP_Train'\n",
    "datafile = os.path.join(dataset_path, 'DMSC.csv')\n",
    "\n",
    "# 停用词表路径\n",
    "stop_words_path = 'D:\\\\Study-_Note\\\\NLP\\\\NLP_Train'\n",
    "\n",
    "# 加载数据\n",
    "raw_data = pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('数据集有{}条记录。'.format(len(raw_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 电影名称\n",
    "print('数据集包含{}部电影。'.format(len(raw_data['Movie_Name_CN'].unique())))\n",
    "print(raw_data['Movie_Name_CN'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 电影平均得分\n",
    "movie_mean_score = raw_data.groupby('Movie_Name_CN')['Star'].mean().sort_values(ascending=False)\n",
    "movie_mean_score.plot(kind='bar')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 去除空值（如果有的话）\n",
    "cln_data = raw_data.dropna().copy()\n",
    "\n",
    "# 建立新的一列，如果打分>=3.0，为正面评价1，否则为负面评价0\n",
    "cln_data['Positively Rated'] = np.where(cln_data['Star'] >= 3, 1, 0)\n",
    "\n",
    "# 数据预览\n",
    "cln_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords1 = [line.rstrip() for line in open(os.path.join(stop_words_path, 'cn_stopwords.txt'), 'r', encoding='utf-8')]\n",
    "stopwords2 = [line.rstrip() for line in open(os.path.join(stop_words_path, 'hit_stopwords.txt'), 'r', encoding='utf-8')]\n",
    "stopwords3 = [line.rstrip() for line in open(os.path.join(stop_words_path, 'scu_stopwords.txt'), 'r', encoding='utf-8')]\n",
    "stopwords4 = [line.rstrip() for line in open(os.path.join(stop_words_path, 'baidu_stopwords.txt'), 'r', encoding='utf-8')]\n",
    "\n",
    "stopwords = stopwords1 + stopwords2 + stopwords3 + stopwords4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 处理文本数据\n",
    "import re\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_text(raw_line):\n",
    "    \"\"\"\n",
    "        处理文本数据\n",
    "        返回分词结果\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 使用正则表达式去除非中文字符\n",
    "    filter_pattern = re.compile('[^\\u4E00-\\u9FD5]+')\n",
    "    chinese_only = filter_pattern.sub('', raw_line)\n",
    "\n",
    "    # 2. 结巴分词+词性标注\n",
    "    word_list = pseg.cut(chinese_only)\n",
    "\n",
    "    # 3. 去除停用词，保留有意义的词性\n",
    "    # 动词，形容词，副词\n",
    "    used_flags = ['v', 'a', 'ad']\n",
    "    meaninful_words = []\n",
    "    for word, flag in word_list:\n",
    "        # \n",
    "        if (word not in stopwords) and (flag in used_flags):\n",
    "            meaninful_words.append(word)\n",
    "    return ' '.join(meaninful_words)\n",
    "\n",
    "# 测试一条记录\n",
    "test_text = cln_data.loc[5, 'Comment']\n",
    "print('原文本：', test_text)\n",
    "print('\\n\\n处理后：', proc_text(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 处理数据集中的所有文本\n",
    "cln_data['Words'] = cln_data['Comment'].apply(proc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cln_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将处理后的数据集保存\n",
    "saved_data = cln_data[['Words', 'Positively Rated']].copy()\n",
    "saved_data.dropna(subset=['Words'], inplace=True)\n",
    "saved_data.to_csv(os.path.join(dataset_path, 'douban_cln_data.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分割训练集与测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_data, X_test_data, y_train, y_test = train_test_split(saved_data['Words'], saved_data['Positively Rated'], test_size=1/4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X__train_data 第一条记录：\\n\\n', X_train_data.iloc[1])\n",
    "print('\\n\\n训练集样本数: {}，测试集样本数：{}'.format(len(X_train_data), len(X_test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# max_features指定语料库中频率最高的词\n",
    "n_dim = 10000\n",
    "vectorizer = TfidfVectorizer(max_features=n_dim)\n",
    "X_train = vectorizer.fit_transform(X_train_data.values)\n",
    "X_test = vectorizer.transform(X_test_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('特征维度：', len(vectorizer.get_feature_names()))\n",
    "print('语料库中top{}的词：'.format(n_dim))\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  建模及预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(C=100)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = lr_model.predict(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
